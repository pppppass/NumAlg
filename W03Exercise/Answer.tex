%! TeX encoding = UTF-8
%! TeX program = LuaLaTeX

\documentclass[english, nochinese]{pnote}
\usepackage{siunitx}
\usepackage[paper]{pdef}
\usepackage{pgf}

\title{Answers to Exercises (Week 03)}
\author{Zhihan Li, 1600010653}
\date{October 4, 2018}

\begin{document}

\maketitle

\textbf{Problem 1. (Page 38 Exercise 18)} \textit{Proof.} Consider the LU decomposition of $ A = L U $ first. Since $A$ is banded with upper and lower bandwidth $n$, the procedure of LU decomposition yields that $L$ is lower triangular with lower bandwidth $n$. This is because the $i$-th Gauss transformation only involves adding multiplies of $i$-th row to $ i + 1, i + 2, \cdots, i + n $-th rows, and therefore the matrix after $i$-th Gauss transformation has upper and lower bandwidth $n$ as a result. Hence, $L$ has lower bandwidth $n$. Denote the diagonal part of $U$ to be $D$, which turns out to be non-singular since $U$ is non-singular. Thus, we have
\begin{equation}
A = L U = \rbr{ U^{\text{T}} D^{-1} } \rbr{ D L^{\text{T}} }
\end{equation}
and therefore $ L = U^{\text{T}} D^{-1} $, $ A = L D L^{\text{T}} $. Since $A$ is positive definite, we obtain $ D \prec 0 $ and
\begin{equation}
A = \rbr{ L D^{ 1 / 2 } } \rbr{ D^{ 1 / 2 } L^{\text{T}} },
\end{equation}
which means $ L D^{ 1 / 2 } $ is exactly the Cholesky factor and has the lower bandwidth $n$. According to conventions from the textbook, the bandwidth is $ n + 1 $.
\hfill$\Box$

\textbf{Problem 2. (Page 38 Exercise 20)} \textit{Proof.} The existence is exactly part of the argument stated in Problem 1. We have proved the existence of $L$ and $D$ such that
\begin{equation}
A = L D L^{\text{T}}
\end{equation}
regardless of the positive definiteness of $A$. For the uniqueness, suppose another pair, say $ \rbr{ \tilde{L}, \tilde{D} } $, satisfies the equation. We have
\begin{equation}
A = L \rbr{ D L^{\text{T}} } = \tilde{L} \rbr{ \tilde{D} \tilde{L}^{\text{T}}}
\end{equation}
and therefore the uniqueness of LU decomposition yields $ L = \tilde{L} $, $ D L^{\text{T}} = \tilde{D} \tilde{L}^{\text{T}} $, which further implies $ D = \tilde{D} $ since the non-singularity of $L$.
\hfill$\Box$

\textbf{Problem 3. (Page 38 Exercise 23)} \textit{Answer.} We first calculate the LDL\textsuperscript{T} decomposition $ A = L D L^{\text{T}} $, which takes $ \frac{1}{3} n^3 + O \rbr{n^2} $ operations. We then calculate the inverse $L^{-1}$, which can be done by performing Gauss transformation to $L$ and $I$ simultaneously. This takes
\begin{equation}
\sum_{ k = 1 }^n 2 k \rbr{ n - k } = \frac{1}{3} n^3 + O \rbr{n^2}
\end{equation}
operations. We then calculate $ D^{-1} L^{-1} $, which takes $ O \rbr{n^2} $ operators. We finally calculate
\begin{equation}
A^{-1} = L^{-\text{T}} \rbr{ D^{-1} L^{-1} },
\end{equation}
this takes
\begin{equation}
\sum_{ k = 1 }^n \rbr{ n + 1 - k } \rbr{ 2 k - 1 } = \frac{1}{3} n^3 + O \rbr{n^2}
\end{equation}
operations. The final number of operators is $ n^3 + O \rbr{n^2} $, and the temporary space we need is $n^2$.

\textbf{Problem 4.} \textit{Answer.} (1) Denote the numerical solution $u$ as the $N^2$-vector
\begin{equation}
u = \msbr{ u_{ 1 1 } & u_{ 1 2 } & \cdots & u_{ 1 N } & u_{ 2 1 } & u_{ 2 2 } & \cdots & u_{ 2 N } & \cdots & u_{ N 1 } & u_{ 2 2 } & \cdots & u_{ N N } }^{\text{T}}.
\end{equation}
Denote the discretized differential operator $L$ as the $ N^2 \times N^2 $ matrix
\begin{equation}
L = \msbr{ A & -\frac{1}{h^2} I & & & & \\ -\frac{1}{h^2} I & A & -\frac{1}{h^2} I & & & \\ & -\frac{1}{h^2} I & A & \ddots & & \\ & & \ddots & \ddots & \ddots & \\ & & & \ddots & A & -\frac{1}{h^2} I \\ & & & & -\frac{1}{h^2} I & A },
\end{equation}
where $A$ is the $ N \times N $ matrix
\begin{equation}
A = \msbr{ \frac{4}{h^2} & -\frac{1}{h^2} & & & & \\ -\frac{1}{h^2} & \frac{4}{h^2} & -\frac{1}{h^2} & & & \\ & -\frac{1}{h^2} & \frac{4}{h^2} & \ddots & & \\ & & \ddots & \ddots & \ddots & \\ & & & \ddots & \frac{4}{h^2} & -\frac{1}{h^2} \\ & & & & -\frac{1}{h^2} & \frac{4}{h^2} }.
\end{equation}
The discretized equation is
\begin{equation}
L u = 0.
\end{equation}

(2) The running time with respect to $n$ is summarized in Figure \ref{Fig:Time}.

\begin{figure}[htb]
{
\centering
\input{Figure1.pgf}
\caption{Running time of different methods}
\label{Fig:Time}
}
{
\small
Here \verb"spsolve" stands for the sparse linear system solver provided by \verb"scipy.sparse.linalg.spsolve", and \verb"solve" stands for the dense linear system solver provided by \verb"numpy.linalg.solve".
}
\end{figure}

It can be seen from the figure that {\color{red}TO BE WRITTEN}.

We also investigate errors of these methods. We compare the $\ell^{\infty}$ error between numerical and analytical solutions in Table \ref{Tbl:NumAna}, and that between numerical solutions in Table \ref{Tbl:NumNum}. In the latter table, the standard solution are chosen to be the ones given by \verb"spsolve".

\begin{table}[htb]
\centering
\small
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
$n$ & \verb"spsolve" & \verb"solve" & LU & Cholesky & LDL & Banded LU \\
\hline
\input{Table1.tbl}
\end{tabular}
\caption{$\ell^{\infty}$ error between numerical and analytical solution}
\label{Tbl:NumAna}
\end{table}

\begin{table}[htb]
\centering
\small
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
$n$ & \verb"spsolve" & \verb"solve" & LU & Cholesky & LDL & Banded LU \\
\hline
\input{Table2.tbl}
\end{tabular}
\caption{$\ell^{\infty}$ error between numerical solutions}
\label{Tbl:NumNum}
\end{table}

From these results, we verify the convergence of the numerical discretization schemes as well as the validity of these linear system solvers.

\textbf{Problem 5.} \textit{Answer.} We list the running time, $\ell^{\infty}$ and $\ell^2$ error between yielded and real solutions in Table \ref{Tbl:Time}, \ref{Tbl:ErrInfty} and \ref{Tbl:Err2} respectively. Here $n$ denotes the size of Hilbert matrix and we vary $n$ to explore the behavior of methods when the matrix gets more and more singular.

\begin{table}[htb]
\centering
\begin{tabular}{|c|c|c|c|c|}
\hline
$n$ & \verb"solve" & LU & Cholesky & LDL \\
\hline
\input{Table3.tbl}
\end{tabular}
\caption{Running time (\Si{s}) of different methods}
\label{Tbl:Time}
\end{table}

\begin{table}[htb]
\centering
\begin{tabular}{|c|c|c|c|c|}
\hline
$n$ & \verb"solve" & LU & Cholesky & LDL \\
\hline
\input{Table4.tbl}
\end{tabular}
\caption{$\ell^{\infty}$ error between yielded and real solutions}
\label{Tbl:ErrInfty}
\end{table}

\begin{table}[htb]
\centering
\begin{tabular}{|c|c|c|c|c|}
\hline
$n$ & \verb"solve" & LU & Cholesky & LDL \\
\hline
\input{Table4.tbl}
\end{tabular}
\caption{$\ell^2$ error between yielded and real solutions}
\label{Tbl:Err2}
\end{table}

It can be seen that from these results that the three hand-written methods are slightly slower than packed solver \verb"numpy.linalg.solve". This is because Python is interpreted and hand-written codes takes noticeably much time than compiled ones. Since the Hilbert matrix is highly singular, all the yielded solutions suffer from huge errors, which is caused by accumulation of tiny numerical rounding errors. Experimentally, LDL solver is slightly more stable than LU solver. However, Cholesky decomposition solver fails quickly because the invalidity of square rooting: the diagonal entry happen to be negative at some time because of rounding error and then square rooting directly raises an error, which leads to Not A Number error eventually.

\end{document}
